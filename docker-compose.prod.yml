version: '3.8'

# Production docker-compose configuration
# Use with: docker-compose -f docker-compose.prod.yml up

networks:
  team-spark-network:
    driver: bridge

services:
  # PostgreSQL database
  postgres:
    image: postgres:16-alpine
    container_name: team-spark-db
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${DB_USER:-postgres}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_DB: ${DB_NAME:-team_spark}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - team-spark-network
    expose:
      - '5432'
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -U ${DB_USER:-postgres}']
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis for caching and sessions
  redis:
    image: redis:7-alpine
    container_name: team-spark-redis
    restart: unless-stopped
    networks:
      - team-spark-network
    expose:
      - '6379'
    command: redis-server --requirepass ${REDIS_PASSWORD}
    healthcheck:
      test: ['CMD', 'redis-cli', '--auth', '${REDIS_PASSWORD}', 'ping']
      interval: 10s
      timeout: 5s
      retries: 5

  # Next.js application
  app:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        - NODE_ENV=production
    container_name: team-spark-app
    restart: unless-stopped
    environment:
      NODE_ENV: production
      DATABASE_URL: postgresql://${DB_USER:-postgres}:${DB_PASSWORD}@postgres:5432/${DB_NAME:-team_spark}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379
      NEXTAUTH_URL: ${NEXTAUTH_URL}
      NEXTAUTH_SECRET: ${NEXTAUTH_SECRET}
      SLACK_CLIENT_ID: ${SLACK_CLIENT_ID}
      SLACK_CLIENT_SECRET: ${SLACK_CLIENT_SECRET}
      SLACK_SIGNING_SECRET: ${SLACK_SIGNING_SECRET}
      RESEND_API_KEY: ${RESEND_API_KEY}
    ports:
      - '${PORT:-3000}:3000'
    networks:
      - team-spark-network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:3000/api/health']
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Background job worker
  worker:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: team-spark-worker
    restart: unless-stopped
    environment:
      NODE_ENV: production
      DATABASE_URL: postgresql://${DB_USER:-postgres}:${DB_PASSWORD}@postgres:5432/${DB_NAME:-team_spark}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379
      RESEND_API_KEY: ${RESEND_API_KEY}
      SLACK_CLIENT_SECRET: ${SLACK_CLIENT_SECRET}
    command: npm run worker
    networks:
      - team-spark-network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy

  # Nginx reverse proxy (optional)
  # nginx:
  #   image: nginx:alpine
  #   container_name: team-spark-nginx
  #   restart: unless-stopped
  #   ports:
  #     - '80:80'
  #     - '443:443'
  #   volumes:
  #     - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
  #     - ./nginx/ssl:/etc/nginx/ssl:ro
  #   networks:
  #     - team-spark-network
  #   depends_on:
  #     - app

# Named volumes
volumes:
  postgres_data:
    name: team-spark-postgres-data-prod
